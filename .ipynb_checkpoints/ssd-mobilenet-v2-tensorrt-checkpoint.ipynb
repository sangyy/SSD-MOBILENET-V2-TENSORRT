{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLT SSD example usecase\n",
    "\n",
    "本教程将详细讲述如何利用NVIDIA Transfer Learning toolkit从头开始训练一个口罩检测的模型，并将模型转换成可以直接部署在NVIDIA GPU（Tesla & Jetson）上的格式.\n",
    "\n",
    "0. [设置环境变量](#head-0)\n",
    "1. [准备数据集和预训练模型](#head-1) <br>\n",
    "    1.1 [将数据集转换成KITTI格式并生成TFrecord文件](#head-1-1) <br>\n",
    "    1.2 [下载预训练模型](#head-1-2) <br>\n",
    "2. [设置训练参数](#head-2)\n",
    "3. [利用NVIDIA Transfer Learning Toolkit训练模型](#head-3)\n",
    "4. [评估模型](#head-4)\n",
    "5. [模型剪枝](#head-5)\n",
    "6. [重新训练剪枝后的模型](#head-6)\n",
    "7. [评估重新训练的模型](#head-7)\n",
    "8. [可视化推理过程](#head-8)\n",
    "9. [模型的导出和部署](#head-9)\n",
    "10. [确认导出模型](#head-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 设置环境变量 <a class=\"anchor\" id=\"head-0\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量，这里请注意KEY是需要您从NGC官网申请的，您可以从以下网址得到您自己的KEY：\n",
    "#https://ngc.nvidia.com/catalog\n",
    "#USER_EXPERIMENT_DIR是我们实验的目录\n",
    "#DATA_DOWNLOAD_DIR是用来保存我们的数据样本和预训练模型\n",
    "#SPECS_DIR是用来保存我们训练设置的超参\n",
    "#以下设置仅代表作者本人的设置目录，需要用户根据自己的实际情况设置更新\n",
    "print(\"Please replace the variable with your key.\")\n",
    "%set_env KEY=OHB1YTZ0Z2RxYTBzdnE3YTNpcnVydmM4cXI6OGVkNDU4ZGQtNjViOC00NzYxLWFhMDUtMjgxMDQ2ZTVmNzAx\n",
    "%set_env USER_EXPERIMENT_DIR=/workspace/tlt_docker_files/mydata/tlt-tensorrt-nano\n",
    "%set_env DATA_DOWNLOAD_DIR=/workspace/tlt_docker_files/mydata/tlt-tensorrt-nano/data\n",
    "%set_env SPECS_DIR=/workspace/tlt_docker_files/mydata/tlt-tensorrt-nano/specs\n",
    "!mkdir -p $USER_EXPERIMENT_DIR\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR\n",
    "!mkdir -p $SPECS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备训练数据集和下载预训练模型 <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证KEY是否设置成功，这个KEY非常重要，用户训练出来的模型在导出和转换时都需要\n",
    "!echo $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NVIDIA官方教程中使用的KITTI目标检测数据集，您可以通过以下网址下载：\n",
    " http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d.\n",
    " \n",
    " 图片下载网址： (http://www.cvlibs.net/download.php?file=data_object_image_2.zip) \n",
    " \n",
    " 标注下载网址： (http://www.cvlibs.net/download.php?file=data_object_label_2.zip) \n",
    " \n",
    " 下载好之后，把数据集放到$DATA_DOWNLOAD_DIR文件夹中."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看上面下载的数据----这步当前实验可以不运行\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR\n",
    "!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_image_2.zip ]; then echo 'Image zip file not found, please download.'; else echo 'Found Image zip file.';fi\n",
    "!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_label_2.zip ]; then echo 'Label zip file not found, please download.'; else echo 'Found Labels zip file.';fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压----这步当前实验可以不运行\n",
    "!unzip -u $DATA_DOWNLOAD_DIR/data_object_image_2.zip -d $DATA_DOWNLOAD_DIR\n",
    "!unzip -u $DATA_DOWNLOAD_DIR/data_object_label_2.zip -d $DATA_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认\n",
    "!ls -l $DATA_DOWNLOAD_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 我们本次实验使用的是网上多个数据集混合的训练样本，VOC格式的.xml数据标注方式，需要用户自己讲标注文件转换成KITTI的格式\n",
    "\n",
    "* 在本次实验当前的目录下，‘data’文件夹下的‘images’保存的是处理好的训练图片，‘labels’文件夹保存的是训练样本的标注文件\n",
    "\n",
    "* \"xmlfiles\"文件夹保存的是转换前的标注文件\n",
    "\n",
    "* \"xml2kitti\"文件夹保存的是转换VOC的.xml文件到KITT格式的工具\n",
    "\n",
    "* changename.py是用来统一更改后缀名的工具\n",
    "\n",
    "* check.py是用来检查图片是否有损坏的工具（比如某个作者之前遇到的错误是某个图片以‘BM’开头，系统会报告格式错误）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 将准备好的训练数据从KITTI格式生成TFrecords格式 <a class=\"anchor\" id=\"head-1-1\"></a>\n",
    "\n",
    "* 更改在specs文件夹中的ssd_tfrecords_kitti_trainval.txt中的参数，指定训练样本的路径\n",
    "* 利用tlt-dataset-convert 生成TFrecords文件\n",
    "* TFRecords文件只需要生成一次既可\n",
    "* 注意这里的路径都是作者本人的环境路径，请用户自行更换成自己的环境路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TFrecords conversion spec file for training\")\n",
    "!cat $SPECS_DIR/ssd_tfrecords_kitti_trainval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个新的文件夹来存储tfrecords文件.\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/tfrecords\n",
    "#创建tfrecords文件 ‘-d’指的是设置文件，就是我们上一步更改的那个，‘-o’指的是输出\n",
    "#目录。\n",
    "!tlt-dataset-convert -d $SPECS_DIR/ssd_tfrecords_kitti_trainval.txt \\\n",
    "                     -o $USER_EXPERIMENT_DIR/tfrecords/kitti_trainval/kitti_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看生成的文件\n",
    "!ls -rlt $USER_EXPERIMENT_DIR/tfrecords/kitti_trainval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 下载预训练模型 <a class=\"anchor\" id=\"head-1-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以通过一下命令下载模型，也可以通过手动的方式下载预训练模型：\n",
    "[ngc.nvidia.com](ngc.nvidia.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看当前目标检测可用的预训练模型\n",
    "!ngc registry model list nvidia/tlt_pretrained_object_detection:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个新的文件夹，存储下载好的预训练模型\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/pretrained_mobilenet_v2/tlt_pretrained_object_detection_mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull pretrained model from NGC\n",
    "!ngc registry model download-version nvidia/tlt_pretrained_object_detection:resnet18 --dest $USER_EXPERIMENT_DIR/pretrained_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"查看下载好的预训练模型.\")\n",
    "!ls -l $USER_EXPERIMENT_DIR/pretrained_mobilenet_v2/tlt_pretrained_object_detection_mobilenet_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 设置训练的超参 <a class=\"anchor\" id=\"head-2\"></a>\n",
    "* 训练数据集\n",
    "    * 为了使用最新生成TFrecords文件，在 `$SPECS_DIR/ssd_train_resnet18_kitti.txt`设置文件路径 \n",
    "    * Update the fold number to use for evaluation. In case of random data split, please use fold 0 only\n",
    "    * 更新测试样本数量，如果随机生成，可以设置成0\n",
    "* 预训练模型\n",
    "* 其他超参比如batch size，learning rate等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $SPECS_DIR/ssd_train_mobilenet_v2_kitti.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 开始训练模型 <a class=\"anchor\" id=\"head-3\"></a>\n",
    "* 需要提供预训练模型、specs文件夹中的设置文件地址以及输出文件夹\n",
    "* 注意：训练课程会持续好几个小时或者一天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_unpruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"如果想用多个GPU可以更改 ‘--gpus’的参数\")\n",
    "!tlt-train ssd -e $SPECS_DIR/ssd_train_mobilenet_v2_kitti.txt \\\n",
    "               -r $USER_EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
    "               -k $KEY \\\n",
    "               -m /workspace-hekun/mydata/tlt-tensorrt-nano/pretrained_mobilenet_v2/tlt_pretrained_object_detection_mobilenet_v2/mobilenet_v2.hdf5 \\\n",
    "               --gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看训练出来的模型\n",
    "!ls /workspace-hekun/mydata/tlt-tensorrt-nano/experiment_dir_unpruned/weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To resume from checkpoint, please uncomment and run this instead. Change last two arguments accordingly.\")\n",
    "# !tlt-train ssd -e $SPECS_DIR/ssd_train_resnet18_kitti.txt \\\n",
    "#                -r $USER_EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
    "#                -k $KEY \\\n",
    "#                -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_resnet18_epoch_001.tlt \\\n",
    "#                --gpus 1 \\\n",
    "#                --initial_epoch 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看训练出来的模型\n",
    "print('Model for each epoch:')\n",
    "print('---------------------')\n",
    "!ls -ltrh $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接下来通过评估的测试结果来选择一个训练效果最好的模型\n",
    "# Note csv epoch number is 1 less than model file epoch. For example, epoch 79 in csv corresponds to _080.tlt\n",
    "!cat $USER_EXPERIMENT_DIR/experiment_dir_unpruned/ssd_training_log_mobilenet_v2.csv\n",
    "%set_env EPOCH=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 评估训练好的模型 <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tlt-evaluate ssd -e $SPECS_DIR/ssd_train_mobilenet_v2_kitti.txt \\\n",
    "                  -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_mobilenet_v2_epoch_$EPOCH.tlt \\\n",
    "                  -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型剪枝 <a class=\"anchor\" id=\"head-5\"></a>\n",
    "* 设置剪枝的阈值\n",
    "* 设置选择剪枝的模型，也就是我们之前通过评估选择的那个模型\n",
    "* 设置输出路径\n",
    "\n",
    "通常，我们需要设置‘-pth’参数来平衡模型的精度与模型的大小（或者说速度）。更高的‘-pth’数值，会让模型更小（更快的推理速度），但是也会降低模型精度。在本次实验中，作者使用的是0.5，如果精度没问题，我们可以增加‘-pth’的数值，来进一步剪枝。反之，我们则需要减小‘-pth’的数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建新的文件夹，保存剪枝后的模型\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#开始模型剪枝\n",
    "!tlt-prune -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_mobilenet_v2_epoch_$EPOCH.tlt \\\n",
    "           -o $USER_EXPERIMENT_DIR/experiment_dir_pruned/ssd_mobilenet_v2_pruned.tlt \\\n",
    "           -eq intersection \\\n",
    "           -pth 0.5 \\\n",
    "           -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看剪枝后的模型\n",
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_pruned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 重新训练剪枝后的模型 <a class=\"anchor\" id=\"head-6\"></a>\n",
    "* 模型在剪枝后需要重新训练\n",
    "* 还需要定义重新训练的参数，比如学习率等。\n",
    "* 注意：重新训练也需要比较长的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 在这里我们打印出训练的超参\n",
    "# 在ssd_retrain_mobilenet_v2_kitti.txt文件中我们需要定义训练设置，\n",
    "# 还可以通过调整数据集来取得更好的训练效果\n",
    "!cat $SPECS_DIR/ssd_retrain_mobilenet_v2_kitti.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个新的文件夹，来保存重新训练的模型\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使剪之后的模型作为预训练模型，重新训练\n",
    "!tlt-train ssd --gpus 1 \\\n",
    "               -e $SPECS_DIR/ssd_retrain_mobilenet_v2_kitti.txt \\\n",
    "               -r $USER_EXPERIMENT_DIR/experiment_dir_retrain \\\n",
    "               -m $USER_EXPERIMENT_DIR/experiment_dir_pruned/ssd_mobilenet_v2_pruned.tlt \\\n",
    "               -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看最新训练出来的模型.\n",
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在，您可以在.CVS文件中查看模型的评估结果\n",
    "# 注意.CVS文件中的序号比实际训练的序号小1, epoch 79 模型指的是第80个.tlt\n",
    "!cat $USER_EXPERIMENT_DIR/experiment_dir_retrain/ssd_training_log_mobilenet_v2.csv\n",
    "%set_env EPOCH=040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 评估预训练模型 <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-evaluate ssd -e $SPECS_DIR/ssd_retrain_mobilenet_v2_kitti.txt \\\n",
    "                  -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_mobilenet_v2_epoch_$EPOCH.tlt \\\n",
    "                  -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 可视化推理结果 <a class=\"anchor\" id=\"head-8\"></a>\n",
    "在这个部分，我们利用tlt-infer在我们训练的模型的基础上进行推理，并且可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running inference for detection on n images\n",
    "!tlt-infer ssd -i $DATA_DOWNLOAD_DIR/infer_images \\\n",
    "               -o $USER_EXPERIMENT_DIR/data/infered_images \\\n",
    "               -e $SPECS_DIR/ssd_train_mobilenet_v2_kitti.txt \\\n",
    "               -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_mobilenet_v2_epoch_$EPOCH.tlt \\\n",
    "               -l $USER_EXPERIMENT_DIR/ssd_infer_labels \\\n",
    "               -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tlt-infer`工具会输出两个文件\n",
    "1. 推理检测出来的图片，保存在`$USER_EXPERIMENT_DIR/ssd_infer_images`文件夹中\n",
    "2. 每一帧的bounding box标注文件会以KITTI的格式保存在`$USER_EXPERIMENT_DIR/ssd_infer_labels`文件夹中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单的写一个可视化工具\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import ceil\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=4, num_images=10):\n",
    "    output_path = os.path.join(os.environ['USER_EXPERIMENT_DIR'], image_dir)\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx / num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里执行可视化工具\n",
    "OUTPUT_PATH = \"data/infered_images\" # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 4 # number of columns in the visualizer grid.\n",
    "IMAGES = 12 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 模型的导出和部署! <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/export\n",
    "# 这里导出的是FP32数据类型的模型，您可以通过更改--data_type的参数来更改导出的模型的数据精度\n",
    "# 比如您可以设置--data_type fp16\n",
    "!tlt-export ssd -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_mobilenet_v2_epoch_$EPOCH.tlt \\\n",
    "                -k $KEY \\\n",
    "                -o $USER_EXPERIMENT_DIR/export/ssd_mobilenet_v2_epoch_040.etlt \\\n",
    "                -e $SPECS_DIR/ssd_retrain_mobilenet_v2_kitti.txt  \\\n",
    "                --batch_size 1 \\\n",
    "                --data_type fp32\n",
    "\n",
    "# 这里有直接导出INT 8 的数据类型的模型的命令 \\\n",
    "# !tlt-export ssd -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt  \\\n",
    "#                 -o $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt \\\n",
    "#                 -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "#                 -k $KEY \\\n",
    "#                 --cal_image_dir  $USER_EXPERIMENT_DIR/data/testing/image_2 \\\n",
    "#                 --data_type int8 \\\n",
    "#                 --batch_size 1 \\\n",
    "#                 --batches 10 \\\n",
    "#                 --cal_cache_file $USER_EXPERIMENT_DIR/export/cal.bin  \\\n",
    "#                 --cal_data_file $USER_EXPERIMENT_DIR/export/cal.tensorfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里展示了tlt-export所有的参数\n",
    "!tlt-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里查看导出的模型\n",
    "print('导出模型:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以通过Docker里面自带的`tlt-converter`工具来转换模型\n",
    "`tlt-converter`工具将会将您训练出来的.etlt模型直接转换成可以部署在NVIDIA TensorRT和Deepstream 上的格式。对于x86设备，您可以直接复制docker中的工具到您自己的环境中\n",
    "但是对于Jetson设备，您需要从下面的网址下载\n",
    "[https://developer.nvidia.com/tlt-converter](https://developer.nvidia.com/tlt-converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成TensorRT engine (FP32)\n",
    "!tlt-converter -k $KEY \\\n",
    "               -d 3,300,300 \\\n",
    "               -o NMS \\\n",
    "               -e $USER_EXPERIMENT_DIR/export/trt--mobilenet_v2_epoch_040.engine \\\n",
    "               -m 1 \\\n",
    "               -t fp32 \\\n",
    "               -i nchw \\\n",
    "               $USER_EXPERIMENT_DIR/export/ssd_mobilenet_v2_epoch_040.etlt\n",
    "\n",
    "# Uncomment to convert to TensorRT engine (INT8).\n",
    "# !tlt-converter -k $KEY  \\\n",
    "#                -d 3,384,1248 \\\n",
    "#                -o NMS \\\n",
    "#                -c $USER_EXPERIMENT_DIR/export/cal.bin \\\n",
    "#                -e $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "#                -b 8 \\\n",
    "#                -m 1 \\\n",
    "#                -t int8 \\\n",
    "#                -i nchw \\\n",
    "#                $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看转换好的推理引擎\n",
    "print('Exported engine:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/export/trt*.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 确认导出模型 <a class=\"anchor\" id=\"head-10\"></a>\n",
    "通过下面的命令来确认导出的engine文件是否可以正确运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用TensorRT engine文件进行推理\n",
    "# 注意这里的tlt-infer 工具只支持batchsize为1，这点非常重要. \n",
    "# 所以请确认在使用tlt-converter工具时 ,使用`-m 1 --batch_size 1`为参数\n",
    "\n",
    "\n",
    "!tlt-infer ssd --trt -p $USER_EXPERIMENT_DIR/export/trt--mobilenet_v2_epoch_040.engine \\\n",
    "                     -e $SPECS_DIR/ssd_train_mobilenet_v2_kitti.txt \\\n",
    "                     -i $DATA_DOWNLOAD_DIR/infer_images \\\n",
    "                     -o $USER_EXPERIMENT_DIR/ssd_infer_images \\\n",
    "                     -t 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
