{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLT DSSD example usecase\n",
    "\n",
    "This notebook shows an example usecase of DSSD object detection using Transfer Learning Toolkit.\n",
    "\n",
    "0. [Set up env variables](#head-0)\n",
    "1. [Prepare dataset and pre-trained model](#head-1) <br>\n",
    "    1.1 [Prepare tfrecords from kitti format dataset](#head-1-1) <br>\n",
    "    1.2 [Download pre-trained model](#head-1-2) <br>\n",
    "2. [Provide training specification](#head-2)\n",
    "3. [Run TLT training](#head-3)\n",
    "4. [Evaluate trained models](#head-4)\n",
    "5. [Prune trained models](#head-5)\n",
    "6. [Retrain pruned models](#head-6)\n",
    "7. [Evaluate retrained model](#head-7)\n",
    "8. [Visualize inferences](#head-8)\n",
    "9. [Deploy](#head-9)\n",
    "10. [Verify deployed model](#head-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "print(\"Please replace the variable with your key.\")\n",
    "%set_env KEY=YOUR_KEY\n",
    "%set_env USER_EXPERIMENT_DIR=/workspace/tlt-experiments/dssd\n",
    "%set_env DATA_DOWNLOAD_DIR=/workspace/tlt-experiments/data\n",
    "%set_env SPECS_DIR=/workspace/examples/dssd/specs\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will be using the KITTI detection dataset for the tutorial. To find more details please visit\n",
    " http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d. Please download the KITTI detection images (http://www.cvlibs.net/download.php?file=data_object_image_2.zip) and labels (http://www.cvlibs.net/download.php?file=data_object_label_2.zip) to $DATA_DOWNLOAD_DIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset is present\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR\n",
    "!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_image_2.zip ]; then echo 'Image zip file not found, please download.'; else echo 'Found Image zip file.';fi\n",
    "!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_label_2.zip ]; then echo 'Label zip file not found, please download.'; else echo 'Found Labels zip file.';fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack \n",
    "!unzip -u $DATA_DOWNLOAD_DIR/data_object_image_2.zip -d $DATA_DOWNLOAD_DIR\n",
    "!unzip -u $DATA_DOWNLOAD_DIR/data_object_label_2.zip -d $DATA_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "!ls -l $DATA_DOWNLOAD_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, if you have your own dataset already in a volume (or folder), you can mount the volume on `DATA_DOWNLOAD_DIR` (or create a soft link). Below shows an example:\n",
    "```bash\n",
    "# if your dataset is in /dev/sdc1\n",
    "mount /dev/sdc1 $DATA_DOWNLOAD_DIR\n",
    "\n",
    "# if your dataset is in folder /var/dataset\n",
    "ln -sf /var/dataset $DATA_DOWNLOAD_DIR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare tfrecords from kitti format dataset <a class=\"anchor\" id=\"head-1-1\"></a>\n",
    "\n",
    "* Update the tfrecords spec file to take in your kitti format dataset\n",
    "* Create the tfrecords using the tlt-dataset-convert \n",
    "* TFRecords only need to be generated once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TFrecords conversion spec file for training\")\n",
    "!cat $SPECS_DIR/dssd_tfrecords_kitti_trainval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new directory for the output tfrecords dump.\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/tfrecords\n",
    "#KITTI trainval\n",
    "!tlt-dataset-convert -d $SPECS_DIR/dssd_tfrecords_kitti_trainval.txt \\\n",
    "                     -o $DATA_DOWNLOAD_DIR/tfrecords/kitti_trainval/kitti_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -rlt $DATA_DOWNLOAD_DIR/tfrecords/kitti_trainval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download pre-trained model <a class=\"anchor\" id=\"head-1-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use NGC CLI to get the pre-trained models. For more details, go to [ngc.nvidia.com](ngc.nvidia.com) and click the SETUP on the navigation bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model list nvidia/tlt_pretrained_object_detection:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/pretrained_resnet18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull pretrained model from NGC\n",
    "!ngc registry model download-version nvidia/tlt_pretrained_object_detection:resnet18 --dest $USER_EXPERIMENT_DIR/pretrained_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $USER_EXPERIMENT_DIR/pretrained_resnet18/tlt_pretrained_object_detection_vresnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Provide training specification <a class=\"anchor\" id=\"head-2\"></a>\n",
    "* Tfrecords for the train datasets\n",
    "    * In order to use the newly generated tfrecords, update the dataset_config parameter in the spec file at `$SPECS_DIR/dssd_train_resnet18_kitti.txt` \n",
    "    * Update the fold number to use for evaluation. In case of random data split, please use fold 0 only\n",
    "    * For sequence wise you may use any fold generated from the dataset convert tool\n",
    "* Pre-trained models\n",
    "* Augmentation parameters for on the fly data augmentation\n",
    "* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $SPECS_DIR/dssd_train_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run TLT training <a class=\"anchor\" id=\"head-3\"></a>\n",
    "* Provide the sample spec file and the output directory location for models\n",
    "* WARNING: training will take several hours or one day to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_unpruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"To run with multigpu, please change --gpus based on the number of available GPUs in your machine.\")\n",
    "!tlt-train dssd -e $SPECS_DIR/dssd_train_resnet18_kitti.txt \\\n",
    "                -r $USER_EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
    "                -k $KEY \\\n",
    "                -m $USER_EXPERIMENT_DIR/pretrained_resnet18/tlt_pretrained_object_detection_vresnet18/resnet_18.hdf5 \\\n",
    "                --gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To resume from checkpoint, please uncomment and run this instead. Change last two arguments accordingly.\")\n",
    "# !tlt-train dssd -e $SPECS_DIR/dssd_train_resnet18_kitti.txt \\\n",
    "#                 -r $USER_EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
    "#                 -k $KEY \\\n",
    "#                 -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/dssd_resnet18_epoch_001.tlt \\\n",
    "#                 --gpus 1 \\\n",
    "#                 --initial_epoch 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model for each epoch:')\n",
    "print('---------------------')\n",
    "!ls -ltrh $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n",
    "# Note csv epoch number is 1 less than model file epoch. For example, epoch 79 in csv corresponds to _080.tlt\n",
    "!cat $USER_EXPERIMENT_DIR/experiment_dir_unpruned/dssd_training_log_resnet18.csv\n",
    "%set_env EPOCH=080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate trained models <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tlt-evaluate dssd -e $SPECS_DIR/dssd_train_resnet18_kitti.txt \\\n",
    "                   -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "                   -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prune trained models <a class=\"anchor\" id=\"head-5\"></a>\n",
    "* Specify pre-trained model\n",
    "* Equalization criterion (`Only for resnets as they have element wise operations or MobileNets.`)\n",
    "* Threshold for pruning.\n",
    "* A key to save and load the model\n",
    "* Output directory to store the model\n",
    "\n",
    "Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold value depends on the dataset and the model. `0.6` in the block below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tlt-prune -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "           -o $USER_EXPERIMENT_DIR/experiment_dir_pruned/dssd_resnet18_pruned.tlt \\\n",
    "           -eq intersection \\\n",
    "           -pth 0.6 \\\n",
    "           -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_pruned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrain pruned models <a class=\"anchor\" id=\"head-6\"></a>\n",
    "* Model needs to be re-trained to bring back accuracy after pruning\n",
    "* Specify re-training specification\n",
    "* WARNING: training will take several hours or one day to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the retrain spec file. \n",
    "# Here we have updated the spec file to include the newly pruned model as a pretrained weights.\n",
    "!cat $SPECS_DIR/dssd_retrain_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining using the pruned model as pretrained weights \n",
    "!tlt-train dssd --gpus 1 \\\n",
    "                -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n",
    "                -r $USER_EXPERIMENT_DIR/experiment_dir_retrain \\\n",
    "                -m $USER_EXPERIMENT_DIR/experiment_dir_pruned/dssd_resnet18_pruned.tlt \\\n",
    "                -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the newly retrained model.\n",
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n",
    "# Note csv epoch number is 1 less than model file epoch. For example, epoch 79 in csv corresponds to _080.tlt\n",
    "!cat $USER_EXPERIMENT_DIR/experiment_dir_retrain/dssd_training_log_resnet18.csv\n",
    "%set_env EPOCH=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate retrained model <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-evaluate dssd -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n",
    "                   -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "                   -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize inferences <a class=\"anchor\" id=\"head-8\"></a>\n",
    "In this section, we run the tlt-infer tool to generate inferences on the trained models and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running inference for detection on n images\n",
    "!tlt-infer dssd -i $DATA_DOWNLOAD_DIR/testing/image_2 \\\n",
    "                -o $USER_EXPERIMENT_DIR/dssd_infer_images \\\n",
    "                -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n",
    "                -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "                -l $USER_EXPERIMENT_DIR/dssd_infer_labels \\\n",
    "                -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tlt-infer` tool produces two outputs. \n",
    "1. Overlain images in `$USER_EXPERIMENT_DIR/dssd_infer_images`\n",
    "2. Frame by frame bbox labels in kitti format located in `$USER_EXPERIMENT_DIR/dssd_infer_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import ceil\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=4, num_images=10):\n",
    "    output_path = os.path.join(os.environ['USER_EXPERIMENT_DIR'], image_dir)\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx / num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the sample images.\n",
    "OUTPUT_PATH = 'dssd_infer_images' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 3 # number of columns in the visualizer grid.\n",
    "IMAGES = 9 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deploy! <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/export\n",
    "# Export in FP32 mode. Change --data_type to fp16 for FP16 mode\n",
    "!tlt-export dssd -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "                 -k $KEY \\\n",
    "                 -o $USER_EXPERIMENT_DIR/export/dssd_resnet18_epoch_$EPOCH.etlt \\\n",
    "                 -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n",
    "                 --batch_size 1 \\\n",
    "                 --data_type fp32\n",
    "\n",
    "# Uncomment to export in INT8 mode (generate calibration cache file). \\\n",
    "# !tlt-export dssd -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/dssd_resnet18_epoch_$EPOCH.tlt  \\\n",
    "#                  -o $USER_EXPERIMENT_DIR/export/dssd_resnet18_epoch_$EPOCH.etlt \\\n",
    "#                  -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n",
    "#                  -k $KEY \\\n",
    "#                  --cal_image_dir  $USER_EXPERIMENT_DIR/data/testing/image_2 \\\n",
    "#                  --data_type int8 \\\n",
    "#                  --batch_size 1 \\\n",
    "#                  --batches 10 \\\n",
    "#                  --cal_cache_file $USER_EXPERIMENT_DIR/export/cal.bin  \\\n",
    "#                  --cal_data_file $USER_EXPERIMENT_DIR/export/cal.tensorfile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note:` In this example, for ease of execution we restrict the number of calibrating batches to 10. TLT recommends the use of at least 10% of the training dataset for int8 calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported model:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify engine generation using the `tlt-converter` utility included with the docker.\n",
    "\n",
    "The `tlt-converter` produces optimized tensorrt engines for the platform that it resides on. Therefore, to get maximum performance, please instantiate this docker and execute the `tlt-converter` command, with the exported `.etlt` file and calibration cache (for int8 mode) on your target device. The converter utility included in this docker only works for x86 devices, with discrete NVIDIA GPU's. \n",
    "\n",
    "For the jetson devices, please download the converter for jetson from the dev zone link [here](https://developer.nvidia.com/tlt-converter). \n",
    "\n",
    "If you choose to integrate your model into deepstream directly, you may do so by simply copying the exported `.etlt` file along with the calibration cache to the target device and updating the spec file that configures the `gst-nvinfer` element to point to this newly exported model. Usually this file is called `config_infer_primary.txt` for detection models and `config_infer_secondary_*.txt` for classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorRT engine (FP16)\n",
    "!tlt-converter -k $KEY \\\n",
    "               -d 3,384,1248 \\\n",
    "               -o NMS \\\n",
    "               -e $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "               -m 1 \\\n",
    "               -t fp16 \\\n",
    "               -i nchw \\\n",
    "               $USER_EXPERIMENT_DIR/export/dssd_resnet18_epoch_$EPOCH.etlt\n",
    "\n",
    "# Uncomment to convert to TensorRT engine (INT8).\n",
    "# !tlt-converter -k $KEY  \\\n",
    "#                -d 3,384,1248 \\\n",
    "#                -o NMS \\\n",
    "#                -c $USER_EXPERIMENT_DIR/export/cal.bin \\\n",
    "#                -e $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "#                -b 8 \\\n",
    "#                -m 1 \\\n",
    "#                -t int8 \\\n",
    "#                -i nchw \\\n",
    "#                $USER_EXPERIMENT_DIR/export/dssd_resnet18_epoch_$EPOCH.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported engine:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/export/trt.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Verify the deployed model <a class=\"anchor\" id=\"head-10\"></a>\n",
    "Verify the converted engine by visualizing TensorRT inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer using TensorRT engine\n",
    "# Note that tlt-infer currently only supports TensorRT engines with batch of 1. \n",
    "# Please make sure to use `-m 1` in tlt-converter and `--batch_size 1` in tlt-export\n",
    "\n",
    "# When integrating with DS, please feel free to use any batch size that the GPU may be able to fit. \n",
    "# The engine batch size once created, cannot be alterred. So if you wish to run with a different batch-size,\n",
    "# please re-run tlt-convert with the new batch-size for DS.\n",
    "\n",
    "!tlt-infer dssd --trt -p $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "                      -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n",
    "                      -i $DATA_DOWNLOAD_DIR/testing/image_2 \\\n",
    "                      -o $USER_EXPERIMENT_DIR/dssd_infer_images \\\n",
    "                      -t 0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
